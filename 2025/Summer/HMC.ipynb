{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc109ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module Name: HMC.ipynb\n",
    "\n",
    "Description:\n",
    "    Making a list of distributions and functions for use in numerical sampling and analysis of approximate convergence. \n",
    "\n",
    "Author: John Gallagher\n",
    "Created: 2025-06-03\n",
    "Last Modified: \n",
    "Version: 1.0.0\n",
    "\n",
    "Dependencies:\n",
    "    - numpy\n",
    "    - scipy\n",
    "    - matplotlib.pyplot\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import gamma\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1234)  # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf24e7",
   "metadata": {},
   "source": [
    "## Some target distribution functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cdbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nongauss_f(x):\n",
    "    \"\"\"Non-gaussian target distribution.\"\"\"\n",
    "    return np.exp(-x**2 * (2 + np.sin(5*x) + np.sin(2*x)))\n",
    "\n",
    "def gauss_f(x):\n",
    "    \"\"\"Gaussian target distribution.\"\"\"\n",
    "    return np.exp(-x**2)\n",
    "def t_dist_f(x, df=3):\n",
    "    \"\"\"t-distribution target distribution.\"\"\"\n",
    "    return gamma((df + 1) / 2) / (np.sqrt(df * np.pi) * gamma(df / 2)) * (1 + x**2 / df)**(-(df + 1) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db8331f",
   "metadata": {},
   "source": [
    "## Metropolis Algorithm (1dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8826dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_step(x, sigma, function):\n",
    "    \"\"\" Perform a single Metropolis-Hastings step.\n",
    "    Args:\n",
    "        x (float): Current state of the chain.\n",
    "        sigma (float): Step size for the proposal distribution.\n",
    "        function (callable): Target distribution function.\n",
    "    \n",
    "    Returns:  \n",
    "        tuple: A tuple containing the new state and a boolean indicating whether the step was accepted.\n",
    "    \"\"\"\n",
    "\n",
    "    proposed_x = np.random.normal(x, sigma)\n",
    "    alpha = min(1, function(proposed_x)/function(x)) #why does this fraction work? Base case is we draw from the center of distributions and we want more information on the curvature.  The smaller probabilties (lower values) are associated with getting more information about the smaller regions. \n",
    "    u = np.random.uniform()\n",
    "    if u < alpha:\n",
    "        value = proposed_x\n",
    "        accepted = True\n",
    "    else:\n",
    "        value = x\n",
    "        accepted = False\n",
    "    return value, accepted\n",
    "def metropolis_sampler(initial_val, function, n=1000, sigma = 1):\n",
    "    \"\"\"\n",
    "    Perform Metropolis-Hastings sampling.\n",
    "\n",
    "    Args:\n",
    "        initial_val (float): Initial value for the chain.\n",
    "        function (callable): Target distribution function.\n",
    "        n (int): Number of samples to generate.\n",
    "        sigma (float): Step size for the proposal distribution.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of tuples containing sampled values and acceptance status.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    current_state = initial_val\n",
    "    for i in range(0, n):\n",
    "        out = metropolis_step(current_state, sigma, function)\n",
    "        current_state = out[0]\n",
    "        results.append(out)\n",
    "    return results\n",
    "\n",
    "def plot_results(self, x_range=(-11, 11), n_points=10000, bins=50):\n",
    "    \"\"\"\n",
    "    Plot the sampling results against the target distribution.\n",
    "    \n",
    "    Args:\n",
    "        x_range (tuple): Range of x values for plotting\n",
    "        n_points (int): Number of points for target function curve\n",
    "        bins (int): Number of histogram bins\n",
    "    \"\"\"\n",
    "    if self.samples is None:\n",
    "        raise ValueError(\"No samples available. Run sample() first.\")\n",
    "        \n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    # Plot histogram of accepted samples\n",
    "    ax1.hist(self.accepted['value'], bins=bins)\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_xlabel('x-Value')\n",
    "    ax1.set_title('Resulting Accepted Distribution vs Target Function')\n",
    "    \n",
    "    # Plot target distribution\n",
    "    ax2 = ax1.twinx()\n",
    "    x_vals = np.linspace(x_range[0], x_range[1], n_points)\n",
    "    y_vals = [self.target_function(x) for x in x_vals]\n",
    "    ax2.plot(x_vals, y_vals, 'r-', label='Target Function')\n",
    "    ax2.set_ylabel('Target Function Value')\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a34b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "sigma = 12\n",
    "sample = metropolis_sampler(0.1, nongauss_f, n = n,sigma=sigma)\n",
    "data = pd.DataFrame(sample)\n",
    "accepted = data[data[1]==True]\n",
    "xval = np.linspace(-11,11, 10000)\n",
    "yval = nongauss_f(xval)\n",
    "fig, plt1 = plt.subplots()\n",
    "\n",
    "# First y-axis with histogram\n",
    "plt1.hist(accepted[0],bins=50)\n",
    "plt1.set_ylabel('Frequency')\n",
    "plt1.set_xlabel('x-Value')\n",
    "plt1.set_title('Resulting Accepted Distribution vs Target Function'\n",
    "               '\\n' \n",
    "               '$f(x) = exp{[(-x^2)(2 + \\sin{(5x)} + \\sin{(2x))]}}$' )\n",
    "\n",
    "# Second y-axis with target distribution\n",
    "color = 'tab:red'\n",
    "plt2 = plt1.twinx()\n",
    "plt2.set_ylabel('Target Function Value')\n",
    "plt2.set_ylim(0,1)\n",
    "plt2.plot(xval, yval, label='Target Function', color = color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee35524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leapfrog_step(t,  q, p, sigma, function, h=0.1):\n",
    "    \"\"\"\n",
    "    Perform a single Leap-Frog step for symplectic integration.\n",
    "\n",
    "    Args:\n",
    "        t (float): Current time.\n",
    "        dt (float): Time step for the integration.\n",
    "        q (np.ndarray): Current state position vector.\n",
    "        p (np.ndarray): Current state momentum vector.\n",
    "        sigma (float): Standard deviation.\n",
    "        function (callable): Target distribution function.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the new state after the Symplectic Euler step.\n",
    "    \"\"\"\n",
    "    # Mass matrix inverse (1/M = 1/sigma^2)\n",
    "    mass_inv = 1. / (sigma**2)\n",
    "\n",
    "    # Kinetic energy term\n",
    "    # Half step for position 0.t*dt*K(t, x)\n",
    "    q_half = q + 0.5 * h *mass_inv * p\n",
    "    # Potential energy term\n",
    "    # V(t,x) = - log(target_function(x))\n",
    "    # Full step for momentum\n",
    "    p_full = p + h * - gradient_term np.log(function(q_half))\n",
    "    # Full step for position\n",
    "    q_full = q_half + 0.5 * h * mass_inv * p_full\n",
    "    return q_full, p_full\n",
    "test0, test1 = leapfrog_step(1, 0.1, 0.2, 12, nongauss_f, h=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hamiltonian(q, p, function, sigma=1.):\n",
    "    \"\"\"\n",
    "    Compute the Hamiltonian of a system given position and momentum.\n",
    "\n",
    "    Args:\n",
    "        q (np.ndarray): Position vector.\n",
    "        p (np.ndarray): Momentum vector.\n",
    "        sigma (float): Standard deviation.\n",
    "\n",
    "    Returns:\n",
    "        float: The Hamiltonian value.\n",
    "    \"\"\"\n",
    "    # Assuming M = sigma^2 * I, where I is the identity matrix\n",
    "    sigma = 1  # This can be adjusted as needed\n",
    "    kinetic_energy = 0.5  * p**2 / (sigma ** 2)\n",
    "    potential_energy = -np.log(function(q))  # Assuming q is the position vector\n",
    "    return kinetic_energy + potential_energy\n",
    "\n",
    "def HMC_step(t, y, sigma, function, h=0.02):\n",
    "    \"\"\"\n",
    "    Perform a single Hamiltonian Monte Carlo step.\n",
    "\n",
    "    Args:\n",
    "        y (float): Current state of the chain.\n",
    "        sigma (float): Step size for the proposal distribution.\n",
    "        function (callable): Target distribution function.\n",
    "        h (float): Step size for the leapfrog integration.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the new state and a boolean indicating whether the step was accepted.\n",
    "    \"\"\"\n",
    "    # initial state\n",
    "    q_initial = y\n",
    "    p_initial = np.random.normal(0, sigma)\n",
    "    \n",
    "    # Perform a leapfrog step for proposed step\n",
    "    q_proposed, p_proposed = leapfrog_step(t, q_initial, p_initial, sigma, function, h)\n",
    "    \n",
    "    # Compute the Hamiltonian for both initial and proposed states\n",
    "    Current_Hamiltonian = Hamiltonian(q_initial, p_initial, function, sigma)\n",
    "    Proposed_Hamiltonian = Hamiltonian(q_proposed, p_proposed, function, sigma)\n",
    "    # Compute the acceptance probability\n",
    "    alpha = min(1, np.exp(Current_Hamiltonian-Proposed_Hamiltonian))\n",
    "    \n",
    "    # Accept or reject the proposed step\n",
    "    u = np.random.uniform()\n",
    "    if u < alpha:\n",
    "        return q_proposed, True\n",
    "    return q_initial, False\n",
    "\n",
    "def HMC_sampler(initial_val, function, n=1000, sigma=1., h = 0.1):\n",
    "    \"\"\"\n",
    "    Perform Hamiltonian Monte Carlo sampling.\n",
    "\n",
    "    Args:\n",
    "        initial_val (float): Initial value for the chain.\n",
    "        function (callable): Target distribution function.\n",
    "        n (int): Number of samples to generate.\n",
    "        sigma (float): Step size for the proposal distribution.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples containing sampled values and acceptance status.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    current_state = initial_val\n",
    "    for i in range(n):\n",
    "        out = HMC_step(1, current_state, sigma, function, h)\n",
    "        current_state = out[0]\n",
    "        results.append(out)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0de59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the sampler\n",
    "n = 30000\n",
    "sigma = 1.\n",
    "initial_val = 0.1\n",
    "h = 0.5\n",
    "samples = HMC_sampler(initial_val, nongauss_f, n=n, sigma=sigma, h=h)\n",
    "# samples = metropolis_sampler(0.1, nongauss_f, n = n,sigma=sigma)\n",
    "\n",
    "# Plot results\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(samples)\n",
    "accepted = data[data[1]==True]\n",
    "fig, plt1 = plt.subplots()\n",
    "plt1.hist(accepted[0], bins=50)\n",
    "# plt1.title('HMC Sampling Results')\n",
    "# plt1.xlabel('Value')\n",
    "# plt1.ylabel('Frequency')\n",
    "\n",
    "# Second y-axis with target distribution\n",
    "yval = nongauss_f(xval)\n",
    "color = 'tab:red'\n",
    "plt2 = plt1.twinx()\n",
    "plt2.set_ylabel('Target Function Value')\n",
    "plt2.set_ylim(0,1)\n",
    "plt2.plot(xval, yval, label='Target Function', color = color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57f580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
