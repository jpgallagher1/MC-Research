{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc109ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module Name: HMC.py\n",
    "\n",
    "Description:\n",
    "    Making a list of distributions and functions for use in numerical sampling and analysis of approximate convergence. \n",
    "\n",
    "Author: John Gallagher\n",
    "Created: 2025-06-03\n",
    "Last Modified: \n",
    "Version: 1.0.0\n",
    "\n",
    "Dependencies:\n",
    "    - numpy\n",
    "    - scipy\n",
    "    - matplotlib.pyplot\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.stats import norm, uniform, expon\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1234)  # For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72cdbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nongauss_f(x):\n",
    "    \"\"\"Non-gaussian target distribution.\"\"\"\n",
    "    return np.exp(-x**2 * (2 + np.sin(5*x) + np.sin(2*x)))\n",
    "\n",
    "def gauss_f(x):\n",
    "    \"\"\"Gaussian target distribution.\"\"\"\n",
    "    return np.exp(-x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8826dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_step(x, sigma, function):\n",
    "    \"\"\" Perform a single Metropolis-Hastings step.\n",
    "    Args:\n",
    "        x (float): Current state of the chain.\n",
    "        sigma (float): Step size for the proposal distribution.\n",
    "        function (callable): Target distribution function.\n",
    "    \n",
    "    Returns:  \n",
    "        tuple: A tuple containing the new state and a boolean indicating whether the step was accepted.\n",
    "    \"\"\"\n",
    "\n",
    "    proposed_x = np.random.normal(x, sigma)\n",
    "    alpha = min(1, function(proposed_x)/function(x)) #why does this fraction work? Base case is we draw from the center of distributions and we want more information on the curvature.  The smaller probabilties (lower values) are associated with getting more information about the smaller regions. \n",
    "    u = np.random.uniform()\n",
    "    if u < alpha:\n",
    "        value = proposed_x\n",
    "        accepted = True\n",
    "    else:\n",
    "        value = x\n",
    "        accepted = False\n",
    "    return value, accepted\n",
    "def metropolis_sampler(initial_val, function, n=1000, sigma = 1):\n",
    "    \"\"\"\n",
    "    Perform Metropolis-Hastings sampling.\n",
    "\n",
    "    Args:\n",
    "        initial_val (float): Initial value for the chain.\n",
    "        function (callable): Target distribution function.\n",
    "        n (int): Number of samples to generate.\n",
    "        sigma (float): Step size for the proposal distribution.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of tuples containing sampled values and acceptance status.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    current_state = initial_val\n",
    "    for i in range(0, n):\n",
    "        out = metropolis_step(current_state, sigma, function)\n",
    "        current_state = out[0]\n",
    "        results.append(out)\n",
    "    return results\n",
    "\n",
    "def plot_results(self, x_range=(-11, 11), n_points=10000, bins=50):\n",
    "    \"\"\"\n",
    "    Plot the sampling results against the target distribution.\n",
    "    \n",
    "    Args:\n",
    "        x_range (tuple): Range of x values for plotting\n",
    "        n_points (int): Number of points for target function curve\n",
    "        bins (int): Number of histogram bins\n",
    "    \"\"\"\n",
    "    if self.samples is None:\n",
    "        raise ValueError(\"No samples available. Run sample() first.\")\n",
    "        \n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    # Plot histogram of accepted samples\n",
    "    ax1.hist(self.accepted['value'], bins=bins)\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_xlabel('x-Value')\n",
    "    ax1.set_title('Resulting Accepted Distribution vs Target Function')\n",
    "    \n",
    "    # Plot target distribution\n",
    "    ax2 = ax1.twinx()\n",
    "    x_vals = np.linspace(x_range[0], x_range[1], n_points)\n",
    "    y_vals = [self.target_function(x) for x in x_vals]\n",
    "    ax2.plot(x_vals, y_vals, 'r-', label='Target Function')\n",
    "    ax2.set_ylabel('Target Function Value')\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a34b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "sigma = 12\n",
    "sample = metropolis_sampler(0.1, nongauss_f, n = n,sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a08c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = MetropolisSampler(target_function=nongauss_f, sigma=12, seed=1234)\n",
    "samples = sampler.sample(initial_value=0.1, n_samples=100000)\n",
    "sampler.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "def leapfrog_step(self, t,  q, p, dt, sigma, function):\n",
    "    \"\"\"\n",
    "    Perform a single Leap-Frog step for symplectic integration.\n",
    "\n",
    "    Args:\n",
    "        t (float): Current time.\n",
    "        dt (float): Time step for the integration.\n",
    "        q (np.ndarray): Current state position vector.\n",
    "        p (np.ndarray): Current state momentum vector.\n",
    "        sigma (float): Standard deviation.\n",
    "        function (callable): Target distribution function.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the new state after the Symplectic Euler step.\n",
    "    \"\"\"\n",
    "    # Kinetic energy term\n",
    "    K = lambda t, x: 0.5 * 1/sigma**2 * np.eye(len(x))  \n",
    "    # Potential energy term\n",
    "    V = lambda t, x: -np.log(function(x))\n",
    "    # Half step for position\n",
    "    q_half = q + 0.5 * dt * K(t, x)\n",
    "    # Full step for momentum\n",
    "    p_full = p + dt * V(t, q_half)\n",
    "    # Full step for position\n",
    "    q_full = q_half + 0.5 * dt * K(t, p_full)\n",
    "    return q_full, p_full\n",
    "\n",
    "def Hamiltonian(q, p, sigma=1):\n",
    "    \"\"\"\n",
    "    Compute the Hamiltonian of a system given position and momentum.\n",
    "\n",
    "    Args:\n",
    "        q (np.ndarray): Position vector.\n",
    "        p (np.ndarray): Momentum vector.\n",
    "        sigma (float): Standard deviation.\n",
    "\n",
    "    Returns:\n",
    "        float: The Hamiltonian value.\n",
    "    \"\"\"\n",
    "    # Assuming M = sigma^2 * I, where I is the identity matrix\n",
    "    sigma = 1  # This can be adjusted as needed\n",
    "    kinetic_energy = 0.5  * np.dot(p, p / (sigma ** 2)) \n",
    "    potential_energy = -np.sum(np.log(q))  # Assuming q is the position vector\n",
    "    return kinetic_energy + potential_energy\n",
    "\n",
    "def HMC_step(t=1, y, sigma, function):\n",
    "    \"\"\"\n",
    "    Perform a single Hamiltonian Monte Carlo step.\n",
    "\n",
    "    Args:\n",
    "        x (float): Current state of the chain.\n",
    "        sigma (float): Step size for the proposal distribution.\n",
    "        function (callable): Target distribution function.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the new state and a boolean indicating whether the step was accepted.\n",
    "    \"\"\"\n",
    "    q_initial = y\n",
    "    p_initial = np.random.normal(np.zeros(len(y)), sigma)\n",
    "    q_proposed, p_proposed = leapfrog_step(t, q_initial, 0.1, sigma, function)\n",
    "    alpha = min(1, np.exp(-Hamiltonian(q_proposted, p_proposed, sigma) - Hamiltonian(q_initial, p_initial, sigma))\n",
    "    u = np.random.uniform()\n",
    "    if u < alpha:\n",
    "        value = proposed_x\n",
    "        accepted = True\n",
    "    else:\n",
    "        value = y\n",
    "        accepted = False\n",
    "    return value, accepted\n",
    "\n",
    "def HMC_sampler(initial_val, function, n=1000, sigma=1):\n",
    "    \"\"\"\n",
    "    Perform Hamiltonian Monte Carlo sampling.\n",
    "\n",
    "    Args:\n",
    "        initial_val (float): Initial value for the chain.\n",
    "        function (callable): Target distribution function.\n",
    "        n (int): Number of samples to generate.\n",
    "        sigma (float): Step size for the proposal distribution.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples containing sampled values and acceptance status.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    current_state = initial_val\n",
    "    for i in range(n):\n",
    "        out = HMC_step(current_state, sigma, function)\n",
    "        current_state = out[0]\n",
    "        results.append(out)\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
